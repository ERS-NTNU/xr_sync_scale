{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7fc346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Flask in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask) (8.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=8.0->Flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->Flask) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install Flask requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db4b274",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from flask import Flask, jsonify, request\n",
    "# import threading\n",
    "\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# @app.route('/hello', methods=['GET'])\n",
    "# def hello_world():\n",
    "#     return jsonify(message=\"you called?\")\n",
    "\n",
    "# @app.route('/echo', methods=['POST'])\n",
    "# def echo():\n",
    "#     data = request.json\n",
    "#     return jsonify(data)\n",
    "\n",
    "# def run_server():\n",
    "#     app.run(port=5000, debug=False)\n",
    "\n",
    "# # Run the server in a thread to avoid blocking the notebook\n",
    "# thread = threading.Thread(target=run_server)\n",
    "# thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4875dcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [24/Jul/2024 02:33:48] \"GET /hello HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/Jul/2024 02:33:48] \"POST /echo HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'you called?'}\n",
      "{'message': 'you are the server!'}\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "\n",
    "# # Sending a GET request to the /hello endpoint\n",
    "# response = requests.get('http://127.0.0.1:5000/hello')\n",
    "# print(response.json())\n",
    "\n",
    "# # Sending a POST request to the /echo endpoint\n",
    "# data = {'message': 'you are the server!'}\n",
    "# response = requests.post('http://127.0.0.1:5000/echo', json=data)\n",
    "# print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b55a147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, send_file, request\n",
    "import requests as req\n",
    "import threading\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "VIDEO_URL = 'http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4'\n",
    "VIDEO_PATH = 'downloaded_video.mp4'\n",
    "\n",
    "@app.route('/get_video', methods=['GET'])\n",
    "def get_video():\n",
    "    # Download the video\n",
    "    video_data = req.get(VIDEO_URL)\n",
    "    \n",
    "    # Save the video to a file\n",
    "    with open(VIDEO_PATH, 'wb') as f:\n",
    "        f.write(video_data.content)\n",
    "    \n",
    "    # Return the video file\n",
    "    return send_file(VIDEO_PATH, mimetype='video/mp4')\n",
    "\n",
    "def run_server():\n",
    "    app.run(port=5000, debug=False)\n",
    "\n",
    "# Run the server in a thread to avoid blocking the notebook\n",
    "server_thread = threading.Thread(target=run_server)\n",
    "server_thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ebf56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [24/Jul/2024 09:36:34] \"GET /get_video HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Wait a bit for the server to start\n",
    "time.sleep(2)\n",
    "\n",
    "# Request the video from the server\n",
    "response = requests.get('http://127.0.0.1:5000/get_video')\n",
    "\n",
    "# Save the video to a file\n",
    "with open('client_video.mp4', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Display the video using OpenCV\n",
    "cap = cv2.VideoCapture('client_video.mp4')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "else:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# server.py\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "# Configuration via CLI\n",
    "parser = argparse.ArgumentParser(description=\"Volumetric Streaming Server\")\n",
    "parser.add_argument('--host', type=str, default='0.0.0.0')\n",
    "parser.add_argument('--buf-port', type=int, default=9001)\n",
    "parser.add_argument('--hb-port', type=int, default=9002)\n",
    "parser.add_argument('--frame-port', type=int, default=9003)\n",
    "parser.add_argument('--frame-rate', type=int, default=30)\n",
    "parser.add_argument('--report-interval', type=float, default=1.0)\n",
    "args = parser.parse_args()\n",
    "\n",
    "clients = {}  # addr -> {'buf_writer', 'prediction'}\n",
    "\n",
    "async def handle_buffer_commands(reader, writer):\n",
    "    addr = writer.get_extra_info('peername')\n",
    "    clients[addr] = {'buf_writer': writer, 'prediction': 0.0}\n",
    "    print(f\"[BufferCmd] Client {addr} connected\")\n",
    "    try:\n",
    "        while True:\n",
    "            await asyncio.sleep(1)\n",
    "    except asyncio.CancelledError:\n",
    "        writer.close()\n",
    "        await writer.wait_closed()\n",
    "\n",
    "async def handle_heartbeat(reader, writer):\n",
    "    addr = writer.get_extra_info('peername')\n",
    "    print(f\"[Heartbeat] Client {addr} connected\")\n",
    "    try:\n",
    "        while True:\n",
    "            data = await reader.readline()\n",
    "            if not data:\n",
    "                break\n",
    "            msg = json.loads(data)\n",
    "            # echo back with timestamp\n",
    "            writer.write((json.dumps({'timestamp': msg['timestamp']}) + '\\n').encode())\n",
    "            await writer.drain()\n",
    "            # record client's prediction if provided\n",
    "            if 'prediction' in msg:\n",
    "                clients[addr]['prediction'] = msg['prediction']\n",
    "    except asyncio.CancelledError:\n",
    "        pass\n",
    "    writer.close()\n",
    "    await writer.wait_closed()\n",
    "    clients.pop(addr, None)\n",
    "\n",
    "async def frame_stream():\n",
    "    frame_interval = 1.0 / args.frame_rate\n",
    "    frame_id = 0\n",
    "    while True:\n",
    "        for addr, info in clients.items():\n",
    "            writer = info['buf_writer']\n",
    "            cmd = {'cmd': 'frame', 'frame_id': frame_id}\n",
    "            writer.write((json.dumps(cmd) + '\\n').encode())\n",
    "            await writer.drain()\n",
    "        frame_id += 1\n",
    "        await asyncio.sleep(frame_interval)\n",
    "\n",
    "async def control_loop():\n",
    "    while True:\n",
    "        if clients:\n",
    "            preds = [info['prediction'] for info in clients.values()]\n",
    "            max_pred = max(preds) if preds else 0\n",
    "            for addr, info in clients.items():\n",
    "                buf_size = max_pred - info['prediction']\n",
    "                cmd = {'buffer_size': buf_size}\n",
    "                writer = info['buf_writer']\n",
    "                writer.write((json.dumps(cmd) + '\\n').encode())\n",
    "                await writer.drain()\n",
    "        await asyncio.sleep(args.report_interval)\n",
    "\n",
    "async def main():\n",
    "    server_buf = await asyncio.start_server(handle_buffer_commands, args.host, args.buf_port)\n",
    "    server_hb  = await asyncio.start_server(handle_heartbeat, args.host, args.hb_port)\n",
    "    print(f\"Server listening on {args.host} ports BUF:{args.buf_port}, HB:{args.hb_port}\")\n",
    "    await asyncio.gather(\n",
    "        server_buf.serve_forever(),\n",
    "        server_hb.serve_forever(),\n",
    "        frame_stream(),\n",
    "        control_loop()\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    asyncio.run(main())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.py\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Volumetric Streaming Client\")\n",
    "parser.add_argument('--server-host', type=str, default='127.0.0.1')\n",
    "parser.add_argument('--buf-port', type=int, default=9001)\n",
    "parser.add_argument('--hb-port', type=int, default=9002)\n",
    "parser.add_argument('--frame-port', type=int, default=9003)\n",
    "parser.add_argument('--client-id', type=int, required=True)\n",
    "parser.add_argument('--history-k', type=int, default=10)\n",
    "parser.add_argument('--heartbeat-interval', type=float, default=1.0)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Logging setup\n",
    "log_file = f\"logs/client_{args.client_id}.csv\"\n",
    "csv_file = open(log_file, 'w', newline='')\n",
    "writer = csv.writer(csv_file)\n",
    "writer.writerow(['frame_id', 'render_ts', 'buffer_size', 'latency', 'prediction', 'residual'])\n",
    "\n",
    "latencies = []\n",
    "predictions = []\n",
    "residuals = []\n",
    "buffer_size = 0.0\n",
    "K = args.history_k\n",
    "\n",
    "def ewma_predict(history):\n",
    "    alpha = 0.3\n",
    "    if len(history) <= 1:\n",
    "        return history[-1] if history else 0.0\n",
    "    pred = history[-1]\n",
    "    for h in reversed(history[:-1]):\n",
    "        pred = alpha * pred + (1 - alpha) * h\n",
    "    return pred\n",
    "\n",
    "async def heartbeat_loop(reader, writer_hb):\n",
    "    global latencies, predictions, residuals\n",
    "    while True:\n",
    "        send_ts = time.time()\n",
    "        msg = {'timestamp': send_ts, 'prediction': predictions[-1] if predictions else 0.0}\n",
    "        writer_hb.write((json.dumps(msg) + '\\n').encode())\n",
    "        await writer_hb.drain()\n",
    "        data = await reader.readline()\n",
    "        if not data:\n",
    "            break\n",
    "        resp = json.loads(data)\n",
    "        recv_ts = time.time()\n",
    "        rtt = recv_ts - resp['timestamp']\n",
    "        one_way = rtt / 2\n",
    "        latencies.append(one_way)\n",
    "        if len(latencies) > K:\n",
    "            latencies.pop(0)\n",
    "        pred = ewma_predict(latencies)\n",
    "        predictions.append(pred)\n",
    "        res = abs(pred - one_way)\n",
    "        residuals.append(res)\n",
    "        await asyncio.sleep(args.heartbeat_interval)\n",
    "\n",
    "async def buffer_listener(reader, writer_buf):\n",
    "    global buffer_size\n",
    "    while True:\n",
    "        data = await reader.readline()\n",
    "        if not data:\n",
    "            break\n",
    "        cmd = json.loads(data)\n",
    "        if 'buffer_size' in cmd:\n",
    "            buffer_size = cmd['buffer_size']\n",
    "\n",
    "async def frame_listener(reader, writer_frame):\n",
    "    global buffer_size\n",
    "    while True:\n",
    "        line = await reader.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        frame = json.loads(line)\n",
    "        if frame.get('cmd') == 'frame':\n",
    "            frame_id = frame['frame_id']\n",
    "            # simulate render\n",
    "            time.sleep(0.001)\n",
    "            render_ts = time.time()\n",
    "            latency = latencies[-1] if latencies else 0.0\n",
    "            prediction = predictions[-1] if predictions else 0.0\n",
    "            residual = residuals[-1] if residuals else 0.0\n",
    "            writer.writerow([frame_id, render_ts, buffer_size, latency, prediction, residual])\n",
    "            csv_file.flush()\n",
    "\n",
    "async def main():\n",
    "    rb, wb = await asyncio.open_connection(args.server_host, args.buf_port)\n",
    "    rh, wh = await asyncio.open_connection(args.server_host, args.hb_port)\n",
    "    rf, wf = await asyncio.open_connection(args.server_host, args.frame_port)\n",
    "\n",
    "    await asyncio.gather(\n",
    "        heartbeat_loop(rh, wh),\n",
    "        buffer_listener(rb, wb),\n",
    "        frame_listener(rf, wf)\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
